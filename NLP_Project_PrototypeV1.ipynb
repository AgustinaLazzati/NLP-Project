{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The core task seems to be creating a rule-based system for language processing, with a particular emphasis on:\n",
        "\n",
        "1) Negation Detection\n",
        "\n",
        "\n",
        "Identifying negative statements\n",
        "Finding negated terms in text\n",
        "Working specifically with Spanish or Catalan language contexts\n",
        "\n",
        "\n",
        "2) Key Objectives\n",
        "\n",
        "\n",
        "Develop a systematic way to parse and analyze text\n",
        "Create explicit rules for understanding language patterns\n",
        "Handle language-specific linguistic nuances\n",
        "Identify specific types of words or phrases (like negations, uncertainties)\n",
        "\n",
        "\n",
        "3) Specific Focus Areas\n",
        "\n",
        "\n",
        "Medical text analysis (suggested by the NegEx reference)\n",
        "Handling special language characteristics:\n",
        "\n",
        "Accented characters\n",
        "Grammatical agreements\n",
        "Verb conjugations\n",
        "Contractions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The Main Challenge\n",
        "Develop a rule-based system that can:\n",
        "\n",
        "\n",
        "Tokenize text\n",
        "\n",
        "Apply linguistic rules\n",
        "\n",
        "Detect specific language patterns\n",
        "\n",
        "Work accurately with Spanish or Catalan language structures\n"
      ],
      "metadata": {
        "id": "8Xls69tNU4qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def separate_clitics(text):\n",
        "    # Regex pattern to identify and separate Catalan clitics (regex made by not me, so we might need fixin)\n",
        "    clitic_pattern = r'(\\w+)-(m\\'|t\\'|s\\'|li|ho|ne)'\n",
        "\n",
        "    # Separate verb and clitics\n",
        "    separated_text = re.sub(clitic_pattern, r'\\1 \\2', text)\n",
        "\n",
        "    return {\n",
        "        'original': text,\n",
        "        'separated': separated_text,\n",
        "        'clitics_detected': re.findall(clitic_pattern, text)\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "text = \"Mira-m'ho, el llibre és interessant.\"\n",
        "result = separate_clitics(text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwyyXVkHHtQs",
        "outputId": "131d0953-b197-45dc-c1fc-7f34bed767e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'original': \"Mira-m'ho, el llibre és interessant.\", 'separated': \"Mira m'ho, el llibre és interessant.\", 'clitics_detected': [('Mira', \"m'\")]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UncertaintyDetector:\n",
        "    def __init__(self, language='catalan'):\n",
        "        self.uncertainty_words = {\n",
        "            'catalan': ['possiblement', 'potser', 'probablement'],\n",
        "            'spanish': ['posiblemente', 'quizás', 'probablemente']\n",
        "        }.get(language, [])\n",
        "\n",
        "    def detect_uncertainty(self, text):\n",
        "        # Tokenize text\n",
        "        tokens = text.split()\n",
        "        uncertain_phrases = []\n",
        "\n",
        "        for i, token in enumerate(tokens):\n",
        "            if token.lower() in self.uncertainty_words:\n",
        "                # Capture context around uncertainty\n",
        "                start = max(0, i - 2)\n",
        "                end = min(len(tokens), i + 3)\n",
        "                uncertain_phrases.append({\n",
        "                    'uncertainty_marker': token,\n",
        "                    'context': ' '.join(tokens[start:end])\n",
        "                })\n",
        "\n",
        "        return uncertain_phrases\n",
        "\n",
        "# Example usage\n",
        "detector = UncertaintyDetector(language='catalan')\n",
        "text = \"Possiblement la teoria necessita més investigació. Potser hi ha altres factors a considerar.\"\n",
        "results = detector.detect_uncertainty(text)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCs2UEQ7Hya8",
        "outputId": "4fa0d470-e11b-4d11-c8bc-57738b064c62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'uncertainty_marker': 'Possiblement', 'context': 'Possiblement la teoria'}, {'uncertainty_marker': 'Potser', 'context': 'més investigació. Potser hi ha'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AgreementChecker:\n",
        "    def __init__(self, language='spanish'):\n",
        "        self.articles = {\n",
        "            'masculine': ['el', 'un', 'este', 'ese'],\n",
        "            'feminine': ['la', 'una', 'esta', 'esa']\n",
        "        }\n",
        "\n",
        "    def check_gender_agreement(self, sentence):\n",
        "        tokens = sentence.split()\n",
        "        agreements = []\n",
        "\n",
        "        for i in range(len(tokens) - 2):\n",
        "            # Check article and noun\n",
        "            if tokens[i] in self.articles['masculine']:\n",
        "                expected_gender = 'masculine'\n",
        "            elif tokens[i] in self.articles['feminine']:\n",
        "                expected_gender = 'feminine'\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            # Simple gender detection (not comprehensive)\n",
        "            if expected_gender == 'masculine' and tokens[i+1].endswith('o'):\n",
        "                agreements.append({\n",
        "                    'status': 'correct',\n",
        "                    'article': tokens[i],\n",
        "                    'noun': tokens[i+1]\n",
        "                })\n",
        "            elif expected_gender == 'feminine' and tokens[i+1].endswith('a'):\n",
        "                agreements.append({\n",
        "                    'status': 'correct',\n",
        "                    'article': tokens[i],\n",
        "                    'noun': tokens[i+1]\n",
        "                })\n",
        "            else:\n",
        "                agreements.append({\n",
        "                    'status': 'incorrect',\n",
        "                    'article': tokens[i],\n",
        "                    'noun': tokens[i+1]\n",
        "                })\n",
        "\n",
        "        return agreements\n",
        "\n",
        "# Example usage\n",
        "checker = AgreementChecker()\n",
        "sentences = [\n",
        "    \"El coche rojo está estacionado.\",\n",
        "    \"La casa grande está limpia.\"\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    results = checker.check_gender_agreement(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(\"Agreements:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ5MoaA_IfE_",
        "outputId": "c97f882a-2a49-423b-fcbf-e8b81f81cbd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: El coche rojo está estacionado.\n",
            "Agreements: []\n",
            "Sentence: La casa grande está limpia.\n",
            "Agreements: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accent_errors(text, language='spanish'):\n",
        "    # Define correct accent patterns for the language (Idk nothing about this language part, accualy just asked chatgpt to make the rules, so we need to work on this)\n",
        "    accent_rules = {\n",
        "        'spanish': {\n",
        "            'á': ['a'], 'é': ['e'], 'í': ['i'], 'ó': ['o'], 'ú': ['u']\n",
        "        },\n",
        "        'catalan': {\n",
        "            'à': ['a'], 'è': ['e'], 'é': ['e'], 'í': ['i'],\n",
        "            'ò': ['o'], 'ó': ['o'], 'ú': ['u']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Tokenize and check each word\n",
        "    errors = []\n",
        "    words = text.split()\n",
        "\n",
        "    for word in words:\n",
        "        for accented_char, base_chars in accent_rules.get(language, {}).items():\n",
        "            if accented_char in word:\n",
        "                # Check if the base character is correct\n",
        "                base_correct = any(base_char in word.lower().replace(accented_char, '')\n",
        "                                   for base_char in base_chars)\n",
        "\n",
        "                if not base_correct:\n",
        "                    errors.append({\n",
        "                        'word': word,\n",
        "                        'incorrect_accent': accented_char\n",
        "                    })\n",
        "\n",
        "    return errors\n",
        "\n",
        "# Example usage\n",
        "text = \"Estó es una pruéba de acentos incorrectos.\"\n",
        "results = check_accent_errors(text, language='spanish')\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B1rdZTYI1l8",
        "outputId": "6d3b3705-538c-4609-fac2-d63d61c7d50a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'word': 'Estó', 'incorrect_accent': 'ó'}, {'word': 'pruéba', 'incorrect_accent': 'é'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLRgeIj3I4jT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}