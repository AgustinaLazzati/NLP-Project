{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fundamentals of Natural Language Processing\n",
    "# Negation and Uncertainty Detection using a Machine-Learning Based Approach\n",
    "\n",
    "*Authors:*\n",
    "\n",
    "> *Anna Blanco, Agustina Lazzati, Stanislav Bultaskii, Queralt Salvadó*\n",
    "\n",
    "*Aims:*\n",
    "> Our goal is to train various Machine Learning based models for each of the two sub-tasks (detection of negation and uncertainty signals, and detection of the negation and uncertainty scopes). In order to do so, we followed the implementation method described by *Enger, Velldal, and Øvrelid (2017)*, which employs a maximum-margin approach for negation detection. However, for our particular application, we also included uncertainty cues and scope detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References:* \n",
    "<br>\n",
    "> Enger, M., Velldal, E., & Øvrelid, L. (2017). *An open-source tool for negation detection: A maximum-margin approach*. Proceedings of the Workshop on Computational Semantics Beyond Events and Roles (SemBEaR), 64–69."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can erase this if you want but the thing is that we need to use the environment that queralt did. You need to write some commands to have the nlp_project (Python) as we have specific libraries. \n",
    "\n",
    "I did that and in the preprocessing it worked but here in order to work I had to run this command above, if it is not needed just avoid them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['es_core_news_sm']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Check installed models\n",
    "print(spacy.util.get_installed_models())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download es_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  neg_cue_label  \n",
      "0               0              0  \n",
      "1               0              0  \n",
      "2               0              0  \n",
      "3               0              0  \n",
      "4               0              0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0  nsubj     VERB                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  neg_cue_label  \n",
      "0               0              0  \n",
      "1               0              0  \n",
      "2               0              0  \n",
      "3               0              0  \n",
      "4               0              0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  unc_cue_label  \n",
      "0               0              0  \n",
      "1               0              0  \n",
      "2               0              0  \n",
      "3               0              0  \n",
      "4               0              0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  unc_cue_label  \n",
      "0               0              0  \n",
      "1               0              0  \n",
      "2               0              0  \n",
      "3               0              0  \n",
      "4               0              0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  neg_scope_label  \n",
      "0               0                0  \n",
      "1               0                0  \n",
      "2               0                0  \n",
      "3               0                0  \n",
      "4               0                0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "       sentence_id  token_id       word      lemma    pos prefix suffix  \\\n",
      "0                0         0                        SPACE                 \n",
      "1                1         0         nº         nº   NOUN     nº     nº   \n",
      "2                1         1   historia   historia   NOUN    his    ria   \n",
      "3                1         2    clinica    clinico    ADJ    cli    ica   \n",
      "4                1         3          :          :  PUNCT      :      :   \n",
      "...            ...       ...        ...        ...    ...    ...    ...   \n",
      "65526         3459        23          *          *    NUM      *      *   \n",
      "65527         3459        24          )          )  PUNCT      )      )   \n",
      "65528         3459        25  age-v-mir  age-v-mir   VERB    age    mir   \n",
      "65529         3459        26        4/4        4/4    NUM    4/4    4/4   \n",
      "65530         3459        27       lopd       lopd    ADJ    lop    opd   \n",
      "\n",
      "       is_punct  is_redacted    dep head_pos  in_single_word_cues  \\\n",
      "0             0            0    dep    SPACE                    0   \n",
      "1             0            0    det     NOUN                    0   \n",
      "2             0            0  nsubj     VERB                    0   \n",
      "3             0            0   amod     NOUN                    0   \n",
      "4             1            0  punct     NOUN                    0   \n",
      "...         ...          ...    ...      ...                  ...   \n",
      "65526         1            1  punct     NOUN                    0   \n",
      "65527         1            0  punct     NOUN                    0   \n",
      "65528         0            0  appos     NOUN                    0   \n",
      "65529         0            0  appos     NOUN                    0   \n",
      "65530         0            0   amod     NOUN                    0   \n",
      "\n",
      "       in_affixal_cues  ends_with_ment  neg_scope_label  \n",
      "0                    0               0                0  \n",
      "1                    0               0                0  \n",
      "2                    0               0                0  \n",
      "3                    0               0                0  \n",
      "4                    0               0                0  \n",
      "...                ...             ...              ...  \n",
      "65526                0               0                0  \n",
      "65527                0               0                0  \n",
      "65528                1               0                0  \n",
      "65529                0               0                0  \n",
      "65530                0               0                0  \n",
      "\n",
      "[65531 rows x 15 columns]\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  unc_scope_label  \n",
      "0               0                0  \n",
      "1               0                0  \n",
      "2               0                0  \n",
      "3               0                0  \n",
      "4               0                0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0  nsubj     VERB                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  unc_scope_label  \n",
      "0               0                0  \n",
      "1               0                0  \n",
      "2               0                0  \n",
      "3               0                0  \n",
      "4               0                0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Document ID: 20331067\n",
      "Sentence 3:\n",
      "--------------------------------------------------\n",
      "WORD            NEG_CUE  NEG_SCOPE  UNC_CUE  UNC_SCOPE\n",
      "--------------------------------------------------\n",
      "no              1        0          0        0\n",
      "intervencions   0        1          0        0\n",
      "quirurgiques    0        1          0        0\n",
      "ni              0        1          0        0\n",
      "altres          0        1          0        0\n",
      "antecedents     0        1          0        0\n",
      "patologics      0        1          0        0\n",
      ".               0        0          0        0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and functions\n",
    "import json\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "from preprocessing import df_svm_neg_test, df_svm_neg_train, df_svm_neg_test, df_svm_unc_train, df_svm_unc_test, df_crf_neg_train, df_crf_neg_test, df_crf_unc_train, df_crf_unc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUE DETECTION USING SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we'll need to vectorize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def prepare_dataframe_for_svm(df, label_col):\n",
    "    drop_cols = [\"sentence_id\", \"token_id\", label_col]\n",
    "    feature_dicts = df.drop(columns=drop_cols).to_dict(orient=\"records\")\n",
    "    labels = df[label_col].tolist()\n",
    "\n",
    "    vectorizer = DictVectorizer(sparse=True)\n",
    "    X = vectorizer.fit_transform(feature_dicts)\n",
    "    y = labels\n",
    "\n",
    "    return X, y, vectorizer\n",
    "\n",
    "\n",
    "def train_and_evaluate_svm(df_train, df_test, label_col, model_name):\n",
    "    X_train, y_train, vec = prepare_dataframe_for_svm(df_train, label_col)\n",
    "    X_test = vec.transform(df_test.drop(columns=[\"sentence_id\", \"token_id\", label_col]).to_dict(orient=\"records\"))\n",
    "    y_test = df_test[label_col].tolist()\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"svm\", LinearSVC(class_weight=\"balanced\", max_iter=5000))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    print(f\"\\n--- Evaluation for {model_name} ---\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    # Save both the model and the vectorizer\n",
    "    dump(pipeline, f\"{model_name}.joblib\")\n",
    "    dump(vec, f\"{model_name}_vectorizer.joblib\")\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for negation cue detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agusl\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Agusl\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation for svm_negation_cue ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.998     0.999     64399\n",
      "           1      0.916     0.996     0.954      1132\n",
      "\n",
      "    accuracy                          0.998     65531\n",
      "   macro avg      0.958     0.997     0.977     65531\n",
      "weighted avg      0.998     0.998     0.998     65531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg_cue_model = train_and_evaluate_svm(\n",
    "    df_train=df_svm_neg_train,\n",
    "    df_test=df_svm_neg_test,\n",
    "    label_col=\"neg_cue_label\",\n",
    "    model_name=\"svm_negation_cue\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for uncertainty cue detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agusl\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Agusl\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation for svm_uncertainty_cue ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.931     0.964    251284\n",
      "           1      0.038     0.987     0.072       686\n",
      "\n",
      "    accuracy                          0.931    251970\n",
      "   macro avg      0.519     0.959     0.518    251970\n",
      "weighted avg      0.997     0.931     0.962    251970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unc_cue_model = train_and_evaluate_svm(\n",
    "    df_train=df_svm_unc_train,\n",
    "    df_test=df_svm_unc_test,\n",
    "    label_col=\"unc_cue_label\",\n",
    "    model_name=\"svm_uncertainty_cue\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2744\n",
      "1     686\n",
      "Name: unc_cue_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def balance_training_data(df, label_col, neg_ratio=4, seed=42):\n",
    "    positives = df[df[label_col] == 1]\n",
    "    negatives = df[df[label_col] == 0].sample(n=len(positives) * neg_ratio, random_state=seed)\n",
    "    df_balanced = pd.concat([positives, negatives]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    return df_balanced\n",
    "\n",
    "df_balanced_unc_train = balance_training_data(df_svm_unc_train, label_col=\"unc_cue_label\", neg_ratio=4)\n",
    "print(df_balanced_unc_train[\"unc_cue_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agusl\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation for svm_uncertainty_cue_balanced ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.929     0.963    251284\n",
      "           1      0.036     0.987     0.070       686\n",
      "\n",
      "    accuracy                          0.929    251970\n",
      "   macro avg      0.518     0.958     0.517    251970\n",
      "weighted avg      0.997     0.929     0.961    251970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_unc_balanced_model = train_and_evaluate_svm(\n",
    "    df_train=df_balanced_unc_train,\n",
    "    df_test=df_svm_unc_test,\n",
    "    label_col=\"unc_cue_label\",\n",
    "    model_name=\"svm_uncertainty_cue_balanced\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCOPE DETECTION USING CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use CRF BIO tagging:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIO tagging** is a way to label each word in a sentence to show if it is part of a scope (like negation or uncertainty). The labels are:\n",
    "\n",
    "* **B** for the **Beginning** of the scope\n",
    "* **I** for **Inside** the scope\n",
    "* **O** for **Outside** the scope\n",
    "\n",
    "We use BIO tagging to help machine learning models, like **CRFs (Conditional Random Fields)**, understand where a scope starts and ends. For example, if a sentence has a negation like “No tiene fiebre”, BIO tagging shows that “No” is the beginning (**B-SCOPE**) and “tiene fiebre” is inside the scope (**I-SCOPE**), while other words would be labeled **O** if they are not part of it.\n",
    "\n",
    "Using BIO makes it easier for the model to learn patterns and detect complete scopes correctly, not just single words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "def to_bio_labels(labels, label_type=\"SCOPE\"):\n",
    "    # Convert lists of binary labels (0/1) into BIO tagging format for scopes\n",
    "    bio_labels = []\n",
    "    prefix = label_type.upper() + '_SCOPE'  # e.g., NEG_SCOPE or UNC_SCOPE\n",
    "    for sent in labels:\n",
    "        bio = []\n",
    "        prev = 0\n",
    "        for i, tag in enumerate(sent):\n",
    "            if tag == 1:\n",
    "                if i == 0 or prev == 0:\n",
    "                    bio.append(f'B-{prefix}')\n",
    "                else:\n",
    "                    bio.append(f'I-{prefix}')\n",
    "            else:\n",
    "                bio.append('O')\n",
    "            prev = tag\n",
    "        bio_labels.append(bio)\n",
    "    return bio_labels\n",
    "\n",
    "def df_to_crf_format(df):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame into a list of feature dictionaries per sentence for CRF input.\n",
    "    Includes original features + contextual features + lexicon-based features.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): must contain columns like 'word', 'pos', 'prefix', 'suffix', etc.\n",
    "\n",
    "    Returns:\n",
    "        List of list of feature dicts (one per token, grouped by sentence)\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    grouped = df.groupby(\"sentence_id\")\n",
    "\n",
    "    for _, group in grouped:\n",
    "        sentence = []\n",
    "        group = group.reset_index(drop=True)  # Reset index so we can use idx in loop\n",
    "\n",
    "        for idx, row in group.iterrows():\n",
    "            word_lower = row['word'].lower()\n",
    "\n",
    "            features = {\n",
    "                'word.lower()': word_lower,\n",
    "                'word.isupper()': row['word'].isupper(),\n",
    "                'word.istitle()': row['word'].istitle(),\n",
    "                'pos': row['pos'],\n",
    "                'pos_prefix': row['pos'][:2] if isinstance(row['pos'], str) else 'NA',\n",
    "                'prefix': row['prefix'],\n",
    "                'suffix': row['suffix'],\n",
    "                'is_punct': row['is_punct'],\n",
    "                'in_single_word_cues': row['in_single_word_cues'],\n",
    "                'in_affixal_cues': row['in_affixal_cues'],\n",
    "                'ends_with_ment': row['ends_with_ment'],\n",
    "                'has_neg_prefix': word_lower.startswith(('un', 'in', 'non', 'dis')),\n",
    "                'has_neg_suffix': word_lower.endswith(('less', \"n't\")),\n",
    "                'is_modal': word_lower in ['might', 'may', 'could', 'would', 'should']\n",
    "            }\n",
    "\n",
    "            # dependency features\n",
    "            if 'dep' in row and 'head_word' in row and 'head_pos' in row:\n",
    "                features.update({\n",
    "                    'dep_label': row['dep'],\n",
    "                    'head_word': str(row['head_word']).lower(),\n",
    "                    'head_pos': row['head_pos']\n",
    "                })\n",
    "\n",
    "            # Contextual features: previous and next token\n",
    "            if idx > 0:\n",
    "                prev_row = group.iloc[idx - 1]\n",
    "                features.update({\n",
    "                    '-1:word.lower()': prev_row['word'].lower(),\n",
    "                    '-1:pos': prev_row['pos']\n",
    "                })\n",
    "            else:\n",
    "                features['BOS'] = True  # Beginning of sentence\n",
    "\n",
    "            if idx < len(group) - 1:\n",
    "                next_row = group.iloc[idx + 1]\n",
    "                features.update({\n",
    "                    '+1:word.lower()': next_row['word'].lower(),\n",
    "                    '+1:pos': next_row['pos']\n",
    "                })\n",
    "            else:\n",
    "                features['EOS'] = True  # End of sentence\n",
    "\n",
    "            sentence.append(features)\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def df_to_labels(df, label_col):\n",
    "    # Extracts label sequences from the DataFrame, grouped by sentence\n",
    "    label_sequences = []\n",
    "    grouped = df.groupby(\"sentence_id\")\n",
    "    for _, group in grouped:\n",
    "        label_list = group[label_col].tolist()\n",
    "        label_sequences.append(label_list)\n",
    "    return label_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train + evaluate CRF model\n",
    "def train_and_evaluate_crf(df_train, df_test, label_col):\n",
    "    # Trains and evaluates a CRF model for BIO tagging using specified label column (e.g., 'neg_scope_label')\n",
    "    scope_type = \"NEG\" if \"neg\" in label_col.lower() else \"UNC\"\n",
    "\n",
    "    X_train = df_to_crf_format(df_train)\n",
    "    y_train_raw = df_to_labels(df_train, label_col)\n",
    "    y_train = to_bio_labels(y_train_raw, label_type=scope_type)\n",
    "\n",
    "    X_test = df_to_crf_format(df_test)\n",
    "    y_test_raw = df_to_labels(df_test, label_col)\n",
    "    y_test = to_bio_labels(y_test_raw, label_type=scope_type)\n",
    "\n",
    "    crf = CRF(algorithm='lbfgs', max_iterations=100, all_possible_transitions=True)\n",
    "    crf.fit(X_train, y_train)\n",
    "    y_pred = crf.predict(X_test)\n",
    "\n",
    "    print(f\"CRF Evaluation for: {label_col.upper()}\")\n",
    "    print(metrics.flat_classification_report(y_test, y_pred))   \n",
    "    \n",
    "    return X_test, y_test, y_pred  # Return these variables for further use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We should try implementing something like a print to see how well it does in sentences (real examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_crf_predictions(df, X, y_true, y_pred, sentence_idx=0):\n",
    "    \"\"\"\n",
    "    Print words, true BIO labels, and predicted BIO labels for a given sentence index.\n",
    "    \"\"\"\n",
    "    grouped = df.groupby(\"sentence_id\")\n",
    "    sentence_ids = list(grouped.groups.keys())\n",
    "\n",
    "    if sentence_idx >= len(sentence_ids):\n",
    "        print(f\"Invalid sentence index {sentence_idx}. Max allowed: {len(sentence_ids) - 1}\")\n",
    "        return\n",
    "\n",
    "    sentence_id = sentence_ids[sentence_idx]\n",
    "    sentence_df = grouped.get_group(sentence_id)\n",
    "\n",
    "    print(f\"\\n--- Sentence {sentence_idx} (ID {sentence_id}) ---\")\n",
    "    print(f\"{'WORD':<15} {'TRUE':<15} {'PRED':<15}\")\n",
    "    print(f\"{'-'*45}\")\n",
    "    for i, row in sentence_df.iterrows():\n",
    "        word = row['word']\n",
    "        true_label = y_true[sentence_idx][row['token_id']]\n",
    "        pred_label = y_pred[sentence_idx][row['token_id']]\n",
    "        print(f\"{word:<15} {true_label:<15} {pred_label:<15}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF for negation scope detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF Evaluation for: NEG_SCOPE_LABEL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " B-NEG_SCOPE       0.97      0.89      0.93      1071\n",
      " I-NEG_SCOPE       0.90      0.79      0.84      2522\n",
      "           O       0.99      1.00      0.99     61938\n",
      "\n",
      "    accuracy                           0.99     65531\n",
      "   macro avg       0.96      0.89      0.92     65531\n",
      "weighted avg       0.99      0.99      0.99     65531\n",
      "\n",
      "\n",
      "--- Sentence 0 (ID 0) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "                O               O              \n",
      "\n",
      "--- Sentence 1 (ID 1) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "nº              O               O              \n",
      "historia        O               O              \n",
      "clinica         O               O              \n",
      ":               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "nºepisodi       O               O              \n",
      ":               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "sexe            O               O              \n",
      ":               O               O              \n",
      "dona            O               O              \n",
      "data            O               O              \n",
      "de              O               O              \n",
      "naixement       O               O              \n",
      ":               O               O              \n",
      "12.05.1977      O               O              \n",
      "edat            O               O              \n",
      ":               O               O              \n",
      "42              O               O              \n",
      "anys            O               O              \n",
      "procedencia     O               O              \n",
      "aguts           O               O              \n",
      "servei          O               O              \n",
      "obstetricia     O               O              \n",
      "data            O               O              \n",
      "d'ingres        O               O              \n",
      "27.09.2019      O               O              \n",
      "data            O               O              \n",
      "d'alta          O               O              \n",
      "01.10.2019      O               O              \n",
      "13:00:00        O               O              \n",
      "ates            O               O              \n",
      "per             O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      ",               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      ";               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      ",               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "*               O               O              \n",
      "informe         O               O              \n",
      "d'alta          O               O              \n",
      "d'hospitalitzacio O               O              \n",
      "motiu           O               O              \n",
      "d'ingres        O               O              \n",
      "induccion       O               O              \n",
      "al              O               O              \n",
      "parto           O               O              \n",
      "por             O               O              \n",
      "pequeño         O               O              \n",
      "para            O               O              \n",
      "la              O               O              \n",
      "edad            O               O              \n",
      "gestacional     O               O              \n",
      "(               O               O              \n",
      "peg             O               O              \n",
      ")               O               O              \n",
      "antecedents     O               O              \n",
      "no              O               O              \n",
      "alergias        B-NEG_SCOPE     B-NEG_SCOPE    \n",
      "medicamentosas  I-NEG_SCOPE     I-NEG_SCOPE    \n",
      "conocidas       O               I-NEG_SCOPE    \n",
      "antcededentes   O               I-NEG_SCOPE    \n",
      "medico-quirurgicos O               I-NEG_SCOPE    \n",
      ":               O               O              \n",
      "protesis        O               O              \n",
      "mamaria         O               O              \n",
      ",               O               O              \n",
      "adenoidectomia  O               O              \n",
      "niega           O               O              \n",
      "habitos         B-NEG_SCOPE     B-NEG_SCOPE    \n",
      "toxicos         I-NEG_SCOPE     I-NEG_SCOPE    \n",
      "medicacio       O               O              \n",
      "habitual        O               O              \n",
      "anafranil25     O               O              \n",
      "mg/             O               O              \n",
      "diario          O               O              \n",
      ".               O               O              \n",
      "\n",
      "--- Sentence 2 (ID 2) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "yodocefol       O               O              \n",
      ".               O               O              \n",
      "\n",
      "--- Sentence 3 (ID 3) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "hierro          O               O              \n",
      "oral            O               O              \n",
      ".               O               O              \n",
      "\n",
      "--- Sentence 4 (ID 4) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "ranitidina      O               O              \n",
      "150             O               O              \n",
      "mg              O               O              \n",
      ".               O               O              \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CRF BIO tagging evaluation for NEGATION scopes\n",
    "X_test, y_test, y_pred = train_and_evaluate_crf(df_crf_neg_train, df_crf_neg_test, \"neg_scope_label\")\n",
    "for i in range(5):\n",
    "    print_crf_predictions(df_crf_neg_test, X_test, y_test, y_pred, sentence_idx=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF for uncertainty scope detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF Evaluation for: UNC_SCOPE_LABEL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " B-UNC_SCOPE       0.89      0.24      0.38       129\n",
      " I-UNC_SCOPE       0.74      0.31      0.44       437\n",
      "           O       0.99      1.00      1.00     64965\n",
      "\n",
      "    accuracy                           0.99     65531\n",
      "   macro avg       0.87      0.52      0.61     65531\n",
      "weighted avg       0.99      0.99      0.99     65531\n",
      "\n",
      "\n",
      "--- Sentence 100 (ID 100) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "cardiovascular  O               O              \n",
      ":               O               O              \n",
      "auscultacion    O               O              \n",
      "cardiaca        O               O              \n",
      "con             O               O              \n",
      "tonos           O               O              \n",
      "ritmicos        O               O              \n",
      "y               O               O              \n",
      "sin             O               O              \n",
      "soplos          O               O              \n",
      ";               O               O              \n",
      "no              O               O              \n",
      "edemas          O               O              \n",
      "en              O               O              \n",
      "miembros        O               O              \n",
      "inferiores      O               O              \n",
      "ni              O               O              \n",
      "lesiones        O               O              \n",
      "cutaneas        O               O              \n",
      ".               O               O              \n",
      "\n",
      "--- Sentence 101 (ID 101) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "respiratorio    O               O              \n",
      ":               O               O              \n",
      "auscultacion    O               O              \n",
      "respiratoria    O               O              \n",
      "con             O               O              \n",
      "murmullo        O               O              \n",
      "vesicular       O               O              \n",
      "conservado      O               O              \n",
      ",               O               O              \n",
      "sin             O               O              \n",
      "ruidos          O               O              \n",
      "patologicos     O               O              \n",
      "añadidos        O               O              \n",
      ".               O               O              \n",
      "\n",
      "--- Sentence 102 (ID 102) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "abdomen         O               O              \n",
      ":               O               O              \n",
      "no              O               O              \n",
      "distendido      O               O              \n",
      ",               O               O              \n",
      "blando          O               O              \n",
      "y               O               O              \n",
      "depresible      O               O              \n",
      ",               O               O              \n",
      "no              O               O              \n",
      "doloroso        O               O              \n",
      "a               O               O              \n",
      "la              O               O              \n",
      "palpacion       O               O              \n",
      ".               O               O              \n",
      "\n",
      "--- Sentence 103 (ID 103) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "no              O               O              \n",
      "se              O               O              \n",
      "palpan          O               O              \n",
      "masas           O               O              \n",
      "ni              O               O              \n",
      "megalias        O               O              \n",
      ",               O               O              \n",
      "ni              O               O              \n",
      "tampoco         O               O              \n",
      "globo           O               O              \n",
      "vesical         O               O              \n",
      ".               O               O              \n",
      "\n",
      "--- Sentence 104 (ID 104) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "no              O               O              \n",
      "signos          O               O              \n",
      "de              O               O              \n",
      "irritacion      O               O              \n",
      "peritoneal      O               O              \n",
      ".               O               O              \n",
      "\n",
      "--- Sentence 105 (ID 105) ---\n",
      "WORD            TRUE            PRED           \n",
      "---------------------------------------------\n",
      "puñopercusion   O               O              \n",
      "lumbar          O               O              \n",
      "bilateral       O               O              \n",
      "negativa        O               O              \n",
      ".               O               O              \n"
     ]
    }
   ],
   "source": [
    "# CRF BIO tagging evaluation for UNCERTAINTY scopes\n",
    "X_test, y_test, y_pred = train_and_evaluate_crf(df_crf_unc_train, df_crf_unc_test, \"unc_scope_label\")\n",
    "for i in range(100,106):\n",
    "    print_crf_predictions(df_crf_unc_test, X_test, y_test, y_pred, sentence_idx=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
