{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fundamentals of Natural Language Processing\n",
    "# Negation and Uncertainty Detection using a Machine-Learning Based Approach\n",
    "\n",
    "*Authors:*\n",
    "\n",
    "> *Anna Blanco, Agustina Lazzati, Stanislav Bultaskii, Queralt Salvadó*\n",
    "\n",
    "*Aims:*\n",
    "> Our goal is to train various Machine Learning based models for each of the two sub-tasks (detection of negation and uncertainty signals, and detection of the negation and uncertainty scopes). In order to do so, we followed the implementation method described by *Enger, Velldal, and Øvrelid (2017)*, which employs a maximum-margin approach for negation detection. However, for our particular application, we also included uncertainty cues and scope detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References:* \n",
    "<br>\n",
    "> Enger, M., Velldal, E., & Øvrelid, L. (2017). *An open-source tool for negation detection: A maximum-margin approach*. Proceedings of the Workshop on Computational Semantics Beyond Events and Roles (SemBEaR), 64–69."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can erase this if you want but the thing is that we need to use the environment that queralt did. You need to write some commands to have the nlp_project (Python) as we have specific libraries. \n",
    "\n",
    "I did that and in the preprocessing it worked but here in order to work I had to run this command above, if it is not needed just avoid them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Check installed models\n",
    "print(spacy.util.get_installed_models())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     --------------------- ------------------ 6.8/12.9 MB 41.7 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 40.3 MB/s eta 0:00:00\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  neg_cue_label  \n",
      "0               0              0  \n",
      "1               0              0  \n",
      "2               0              0  \n",
      "3               0              0  \n",
      "4               0              0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0  nsubj     VERB                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  neg_cue_label  \n",
      "0               0              0  \n",
      "1               0              0  \n",
      "2               0              0  \n",
      "3               0              0  \n",
      "4               0              0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  unc_cue_label  \n",
      "0               0              0  \n",
      "1               0              0  \n",
      "2               0              0  \n",
      "3               0              0  \n",
      "4               0              0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  unc_cue_label  \n",
      "0               0              0  \n",
      "1               0              0  \n",
      "2               0              0  \n",
      "3               0              0  \n",
      "4               0              0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  neg_scope_label  \n",
      "0               0                0  \n",
      "1               0                0  \n",
      "2               0                0  \n",
      "3               0                0  \n",
      "4               0                0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "       sentence_id  token_id       word      lemma    pos prefix suffix  \\\n",
      "0                0         0                        SPACE                 \n",
      "1                1         0         nº         nº   NOUN     nº     nº   \n",
      "2                1         1   historia   historia   NOUN    his    ria   \n",
      "3                1         2    clinica    clinico    ADJ    cli    ica   \n",
      "4                1         3          :          :  PUNCT      :      :   \n",
      "...            ...       ...        ...        ...    ...    ...    ...   \n",
      "65526         3459        23          *          *    NUM      *      *   \n",
      "65527         3459        24          )          )  PUNCT      )      )   \n",
      "65528         3459        25  age-v-mir  age-v-mir   VERB    age    mir   \n",
      "65529         3459        26        4/4        4/4    NUM    4/4    4/4   \n",
      "65530         3459        27       lopd       lopd    ADJ    lop    opd   \n",
      "\n",
      "       is_punct  is_redacted    dep head_pos  in_single_word_cues  \\\n",
      "0             0            0    dep    SPACE                    0   \n",
      "1             0            0    det     NOUN                    0   \n",
      "2             0            0  nsubj     VERB                    0   \n",
      "3             0            0   amod     NOUN                    0   \n",
      "4             1            0  punct     NOUN                    0   \n",
      "...         ...          ...    ...      ...                  ...   \n",
      "65526         1            1  punct     NOUN                    0   \n",
      "65527         1            0  punct     NOUN                    0   \n",
      "65528         0            0  appos     NOUN                    0   \n",
      "65529         0            0  appos     NOUN                    0   \n",
      "65530         0            0   amod     NOUN                    0   \n",
      "\n",
      "       in_affixal_cues  ends_with_ment  neg_scope_label  \n",
      "0                    0               0                0  \n",
      "1                    0               0                0  \n",
      "2                    0               0                0  \n",
      "3                    0               0                0  \n",
      "4                    0               0                0  \n",
      "...                ...             ...              ...  \n",
      "65526                0               0                0  \n",
      "65527                0               0                0  \n",
      "65528                1               0                0  \n",
      "65529                0               0                0  \n",
      "65530                0               0                0  \n",
      "\n",
      "[65531 rows x 15 columns]\n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0   ROOT     NOUN                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  unc_scope_label  \n",
      "0               0                0  \n",
      "1               0                0  \n",
      "2               0                0  \n",
      "3               0                0  \n",
      "4               0                0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "   sentence_id  token_id      word     lemma    pos prefix suffix  is_punct  \\\n",
      "0            0         0                      SPACE                       0   \n",
      "1            1         0        nº        nº   NOUN     nº     nº         0   \n",
      "2            1         1  historia  historia   NOUN    his    ria         0   \n",
      "3            1         2   clinica   clinico    ADJ    cli    ica         0   \n",
      "4            1         3         :         :  PUNCT      :      :         1   \n",
      "\n",
      "   is_redacted    dep head_pos  in_single_word_cues  in_affixal_cues  \\\n",
      "0            0    dep    SPACE                    0                0   \n",
      "1            0    det     NOUN                    0                0   \n",
      "2            0  nsubj     VERB                    0                0   \n",
      "3            0   amod     NOUN                    0                0   \n",
      "4            0  punct     NOUN                    0                0   \n",
      "\n",
      "   ends_with_ment  unc_scope_label  \n",
      "0               0                0  \n",
      "1               0                0  \n",
      "2               0                0  \n",
      "3               0                0  \n",
      "4               0                0  \n",
      "---------------------------------------\n",
      "\n",
      "\n",
      "Document ID: 20331067\n",
      "Sentence 3:\n",
      "--------------------------------------------------\n",
      "WORD            NEG_CUE  NEG_SCOPE  UNC_CUE  UNC_SCOPE\n",
      "--------------------------------------------------\n",
      "no              1        0          0        0\n",
      "intervencions   0        1          0        0\n",
      "quirurgiques    0        1          0        0\n",
      "ni              0        1          0        0\n",
      "altres          0        1          0        0\n",
      "antecedents     0        1          0        0\n",
      "patologics      0        1          0        0\n",
      ".               0        0          0        0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and functions\n",
    "import json\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "from preprocessing import df_svm_neg_test, df_svm_neg_test, df_svm_unc_train, df_svm_unc_test, df_crf_neg_train, df_crf_neg_test, df_crf_unc_train, df_crf_unc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUE DETECTION USING CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we'll need to vectorize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for negation cue detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM for uncertainty cue detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCOPE DETECTION USING CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use CRF BIO tagging:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIO tagging** is a way to label each word in a sentence to show if it is part of a scope (like negation or uncertainty). The labels are:\n",
    "\n",
    "* **B** for the **Beginning** of the scope\n",
    "* **I** for **Inside** the scope\n",
    "* **O** for **Outside** the scope\n",
    "\n",
    "We use BIO tagging to help machine learning models, like **CRFs (Conditional Random Fields)**, understand where a scope starts and ends. For example, if a sentence has a negation like “No tiene fiebre”, BIO tagging shows that “No” is the beginning (**B-SCOPE**) and “tiene fiebre” is inside the scope (**I-SCOPE**), while other words would be labeled **O** if they are not part of it.\n",
    "\n",
    "Using BIO makes it easier for the model to learn patterns and detect complete scopes correctly, not just single words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "def to_bio_labels(labels):\n",
    "    # Convert lists of binary labels (0/1) into BIO tagging format for scopes\n",
    "\n",
    "    bio_labels = []\n",
    "    for sent in labels:\n",
    "        bio = []\n",
    "        prev = 'O'\n",
    "        for i, tag in enumerate(sent):\n",
    "            if tag == 1:\n",
    "                if i == 0 or prev == 0:\n",
    "                    bio.append('B-SCOPE')\n",
    "                else:\n",
    "                    bio.append('I-SCOPE')\n",
    "            else:\n",
    "                bio.append('O')\n",
    "            prev = tag\n",
    "        bio_labels.append(bio)\n",
    "    return bio_labels\n",
    "\n",
    "def df_to_crf_format(df):\n",
    "    # Convert a DataFrame into a list of feature dictionaries per sentence for CRF input\n",
    "    sentences = []\n",
    "    grouped = df.groupby(\"sentence_id\")\n",
    "    for _, group in grouped:\n",
    "        sentence = []\n",
    "        for _, row in group.iterrows():\n",
    "            features = {\n",
    "                'word.lower()': row['word'].lower(),\n",
    "                'word.isupper()': row['word'].isupper(),\n",
    "                'word.istitle()': row['word'].istitle(),\n",
    "                'pos': row['pos'],\n",
    "                'prefix': row['prefix'],\n",
    "                'suffix': row['suffix'],\n",
    "                'is_punct': row['is_punct'],\n",
    "                'in_single_word_cues': row['in_single_word_cues'],\n",
    "                'in_affixal_cues': row['in_affixal_cues'],\n",
    "                'ends_with_ment': row['ends_with_ment']\n",
    "            }\n",
    "            sentence.append(features)\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def df_to_labels(df, label_col):\n",
    "    # Extracts label sequences from the DataFrame, grouped by sentence\n",
    "    label_sequences = []\n",
    "    grouped = df.groupby(\"sentence_id\")\n",
    "    for _, group in grouped:\n",
    "        label_list = group[label_col].tolist()\n",
    "        label_sequences.append(label_list)\n",
    "    return label_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_crf(df_train, df_test, label_col):\n",
    "    # Trains and evaluates a CRF model for BIO tagging using specified label column (e.g., 'neg_scope_label')\n",
    "    X_train = df_to_crf_format(df_train)\n",
    "    y_train_raw = df_to_labels(df_train, label_col)\n",
    "    y_train = to_bio_labels(y_train_raw)\n",
    "\n",
    "    X_test = df_to_crf_format(df_test)\n",
    "    y_test_raw = df_to_labels(df_test, label_col)\n",
    "    y_test = to_bio_labels(y_test_raw)\n",
    "\n",
    "    crf = CRF(algorithm='lbfgs', max_iterations=100)\n",
    "    crf.fit(X_train, y_train)\n",
    "    y_pred = crf.predict(X_test)\n",
    "\n",
    "    print(f\"CRF Evaluation for: {label_col}\")\n",
    "    print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF for negation scope detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF Evaluation for: neg_scope_label\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-SCOPE       0.87      0.46      0.60      1071\n",
      "     I-SCOPE       0.74      0.56      0.64      2522\n",
      "           O       0.97      0.99      0.98     61938\n",
      "\n",
      "    accuracy                           0.97     65531\n",
      "   macro avg       0.86      0.67      0.74     65531\n",
      "weighted avg       0.96      0.97      0.96     65531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CRF BIO tagging evaluation for NEGATION scopes\n",
    "train_and_evaluate_crf(df_crf_neg_train, df_crf_neg_test, \"neg_scope_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should try implementing something like a print to see how well it does in sentences (real examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF for uncertainty scope detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
