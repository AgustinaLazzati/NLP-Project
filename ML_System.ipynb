{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fundamentals of Natural Language Processing\n",
    "# Negation and Uncertainty Detection using a Machine-Learning Based Approach\n",
    "\n",
    "*Authors:*\n",
    "\n",
    "> *Anna Blanco, Agustina Lazzati, Stanislav Bultaskii, Queralt Salvadó*\n",
    "\n",
    "*Aims:*\n",
    "> Our goal is to train various Machine Learning based models for each of the two sub-tasks (detection of negation and uncertainty signals, and detection of the negation and uncertainty scopes). In order to do so, we followed the implementation method described by *Enger, Velldal, and Øvrelid (2017)*, which employs a maximum-margin approach for negation detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References:* \n",
    "<br>\n",
    "> Enger, M., Velldal, E., & Øvrelid, L. (2017). *An open-source tool for negation detection: A maximum-margin approach*. Proceedings of the Workshop on Computational Semantics Beyond Events and Roles (SemBEaR), 64–69."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and functions\n",
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "from utils import preprocess_text, extract_negations_and_uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we will load all the data as a dictionary, remove unnecessary information such as '*', normalize whitespaces, and convert it into a proper format, so that we can then work with it. To do this, we will separate the texts from the prediction information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Load JSON data and return raw dict\"\"\"\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Extract texts and predictions from loaded data\"\"\"\n",
    "    texts = []\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        sentence = preprocess_text(data['data'][i]['text'], keep_case=False)\n",
    "        texts.append(sentence)\n",
    "        predictions.append(data['predictions'][i])\n",
    "\n",
    "    return texts, predictions\n",
    "\n",
    "# Load train and test data\n",
    "train_data = load_data('negacio_train_v2024.json')\n",
    "test_data = load_data('negacio_test_v2024.json')\n",
    "\n",
    "# Convert data into a DataFrame for simplicity\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Preprocess it and obtain both the texts and the predictions\n",
    "train_texts, train_preds = preprocess_data(train_df)\n",
    "test_texts, test_preds = preprocess_data(test_df)\n",
    "\n",
    "# Extract list of negations and uncertainties\n",
    "train_negation_cues, train_uncertainty_cues = extract_negations_and_uncertainties(train_df)\n",
    "test_negation_cues, test_uncertainty_cues = extract_negations_and_uncertainties(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define a function to extract only the annotations from the predictions, those annotations will be used later to align them with the token indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 449, 'end': 452, 'labels': ['NEG']}\n"
     ]
    }
   ],
   "source": [
    "def extract_annotations_grouped(preds):\n",
    "    \"\"\"Extracts annotations from the predictions format, grouped per text\"\"\"\n",
    "    all_annotations = []\n",
    "\n",
    "    for pred in preds:\n",
    "        text_annotations = []\n",
    "        for result_entry in pred:\n",
    "            for result in result_entry['result']:\n",
    "                value = result['value']\n",
    "                text_annotations.append({\n",
    "                    'start': value['start'],\n",
    "                    'end': value['end'],\n",
    "                    'labels': value['labels']\n",
    "                })\n",
    "        all_annotations.append(text_annotations)\n",
    "\n",
    "    return all_annotations\n",
    "\n",
    "train_annotations = extract_annotations_grouped(train_preds)\n",
    "test_annotations = extract_annotations_grouped(test_preds)\n",
    "\n",
    "# Show an example of a single annotation information\n",
    "print(train_annotations[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `spacy` for tokenization and sentence splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nº', 'historia', 'clinica', ':', 'REDACTED', 'REDACTED', 'REDACTED', 'nºepisodi', ':', 'REDACTED', 'sexe', ':', 'home', 'data', 'de', 'naixement', ':', '16.05.1936', 'edat', ':', '82', 'anys', 'procedencia', 'cex', 'mateix', 'hosp', 'servei', 'urologia', 'data', \"d'ingres\", '24.07.2018', 'data', \"d'alta\", '25.07.2018', '08:54:04', 'ates', 'per', 'REDACTED', ',', 'REDACTED', ';', 'REDACTED', ',', 'REDACTED', 'informe', \"d'alta\", \"d'hospitalitzacio\", 'motiu', \"d'ingres\", 'paciente', 'que', 'ingresa', 'de', 'forma', 'programada', 'para', 'realizacion', 'de', 'uretrotomia', 'interna', '.', 'antecedents', 'alergia', 'a', 'penicilina', 'y', 'cloramfenicol', '.', 'no', 'habitos', 'toxicos', '.', 'antecedentes', 'medicos', ':', 'bloqueo', 'auriculoventricular', 'de', 'primer', 'grado', 'hipertension', 'arterial', '.', 'diverticulosis', 'extensa', 'insuficiencia', 'renal', 'cronica', 'colelitiasis', 'antecedentes', 'quirurgicos', ':', 'exeresis', 'de', 'lesiones', 'cutaneas', 'con', 'anestesia', 'local', 'protesis', 'total', 'de', 'cadera', 'cordectomia', 'herniorrafia', 'inguinal', 'proces', 'actual', 'varon', 'de', '81a', 'que', 'a', 'raiz', 'de', 'episodio', 'de', 'hematuria', 'macroscopica', 'se', 'realiza', 'cistoscopia', 'que', 'es', 'negativa', 'para', 'lesiones', 'malignas', 'pero', 'se', 'objetiva', 'estenosis', 'de', 'uretra', '.', 'se', 'intentan', 'dilataciones', 'progresivas', 'en', 'el', 'gabinete', 'de', 'urologia', 'sin', 'exito', '.', 'se', 'solicita', 'estudio', 'de', 'imagen', 'que', 'confirma', 'la', 'existencia', 'de', 'estenosis', 'a', 'nivel', 'd', 'uretra', 'bulbar', 'por', 'lo', 'que', 'se', 'indica', 'uretrtomia', 'interna', '.', 'exploracio', 'complementaria', 'uretrocistografia', 'retrograda', '+', 'cums', '(', '11/2017', '):', 'la', 'uretrografia', 'retrograda', 'muestra', 'una', 'uretra', 'anterior', 'con', 'dos', 'estenosis', 'focales', 'a', 'nivel', 'de', 'uretra', 'peneana', 'y', 'bulbar', ',', 'aunque', 'se', 'observa', 'paso', 'de', 'contraste', 'retrogrado', 'a', 'vejiga', '.', 'vejiga', 'de', 'correcta', 'capacidad', '(', '250', 'cc', 'de', 'contraste', ')', ',', 'de', 'paredes', 'trabeculadas', 'y', 'con', 'diverticulos', ',', 'el', 'mayor', 'de', 'ellos', 'en', 'cara', 'posterolateral', 'izquierda', ',', 'sin', 'observarse', 'defectos', 'de', 'replecion', '.', 'la', 'uretrografia', 'miccional', 'muestra', 'una', 'uretra', 'prostatica', 'dilatada', ',', 'sin', 'claras', 'estenosis', 'focales', 'confirmandose', 'la', 'existencia', 'de', 'las', 'dos', 'estenosis', 'de', 'uretra', 'anterior', 'descritas', 'previamente', '.', 'moderado', 'residuo', 'postmiccional', 'en', 'vejiga', 'asi', 'como', 'en', 'el', 'interior', 'del', 'diverticulo', 'posterolateral', 'izquierdo', 'descrito', '.', 'uretroscopia', '(', '10/2017', ')', 'falsa', 'via', 'a', 'nivel', 'de', 'uretra', 'peneana', ',', 'siguiendo', 'la', 'uretra', 'se', 'detecta', 'gran', 'estenosis', 'que', 'no', 'permite', 'el', 'paso', 'de', 'una', 'guia', '.', 'nhc', 'REDACTED', 'REDACTED', 'REDACTED', '(', 'REDACTED', ')', 'age-v-uro', '1/2', 'lopd', 'evolucio', 'clinica', 'el', '24', 'de', 'julio', 'de', '2018', 'con', 'el', 'consentimiento', 'informado', 'del', 'paciente', 'y', 'sin', 'contraindicacion', 'preoperatoria', 'se', 'realiza', 'uretrotomia', 'interna', 'sin', 'incidencias', '.', 'tras', 'el', 'procedimiento', 'el', 'paciente', 'es', 'trasladado', 'a', 'la', 'planta', 'de', 'hospitalizacion', 'siendo', 'portador', 'de', 'lavado', 'vesical', 'continuo', '.', 'posteriormente', 'se', 'mantiene', 'en', 'buen', 'estado', 'general', ',', 'afebril', ',', 'hemodinamicamente', 'estable', 'y', 'con', 'buen', 'control', 'del', 'dolor', '.', 'aclarado', 'progresivo', 'de', 'la', 'orina', 'con', 'los', 'lavados', 'vesicales', 'continuos', ',', 'que', 'permiten', 'su', 'retirada', ',', 'conserva', 'correcta', 'diuresis', '.', 'tolerancia', 'correcta', 'a', 'dieta', 'oral', '.', 'dada', 'la', 'buena', 'evolucion', 'se', 'decide', 'alta', 'domiciliaria', 'siendo', 'portador', 'de', 'sonda', 'vesical', '.', 'orientacio', 'diagnostica', 'n40.0', 'hiperplasia', 'prostatica', 'benigna', 'sense', 'simptomes', 'en', 'les', 'vies', 'urinaries', 'inferiors', 'procediments', '04.81', 'injeccio', 'en', 'el', 'nervi', 'periferic', \"d'anestesic\", 'per', 'a', 'analgesia', '58.0', 'uretrotomia', '.', 'excisio', 'de', 'septe', 'uretral', ',', 'uretrostomia', 'perineal', ',', 'extraccio', 'de', 'calcul', 'uretral', 'per', 'incisio', 'sonda', 'vesical', 'profilaxis', 'antibiotica', ',', 'antilucerosa', 'y', 'antitrombotica', 'tractament', 'i', 'recomanacions', 'a', \"l'alta\", '-abundante', 'ingesta', 'de', 'liquidos', 'entorno', 'a', 'dos', 'litros', 'y', 'medio', 'de', 'agua', 'al', 'dia', '.', '-puede', 'orinar', 'con', 'restos', 'de', 'sangre', 'durante', 'las', 'proximas', 'semanas', '.', '-es', 'normal', 'que', 'sienta', 'escozor', 'al', 'orinar', 'y', 'que', 'tenga', 'algun', 'escape', 'de', 'orina', 'y', 'urgencia', 'miccional', 'al', 'retirar', 'la', 'sonda', 'vesical', '.', 'mantener', 'sonda', 'vesical', 'durante', '14', 'dias', '(', 'dos', 'semanas', ')', '.', 'ciprofloxacino', '500', 'mg', 'cada', '12h', 'durante', 'dos', 'semanas', '.', '-paracetamol', '1', 'g', 'cada', '8', 'horas', 'si', 'molestias', '.', '-si', 'fiebre', 'mayor', 'de', '38ºc', ',', 'empeoramiento', 'claro', 'del', 'estado', 'general', 'o', 'imposibilidad', 'miccional', 'por', 'obstruccion', 'de', 'sonda', 'vesical', 'o', 'despues', 'de', 'su', 'retirada', ',', 'consultar', 'con', 'el', 'servicio', 'de', 'urgencias', '.', '-control', 'en', 'consultas', 'externas', 'de', 'urologia', 'segun', 'cita', 'en', 'hoja', 'adjunta', '.', 'destinacio', 'a', \"l'alta\", ':', 'a', 'domicili', 'nhc', 'REDACTED', 'REDACTED', 'REDACTED', '(', 'REDACTED', ')', 'age-v-uro', '2/2', 'lopd']\n"
     ]
    }
   ],
   "source": [
    "#nlp = spacy.load('xx_ent_wiki_sm') # supports both spanish and catalan\n",
    "\n",
    "nlp_es = spacy.load(\"es_core_news_sm\") # Spanish\n",
    "nlp_ca = spacy.load(\"ca_core_news_sm\") # Catalan\n",
    "\n",
    "def tokenize_sentences(data):\n",
    "    \"\"\"Splits texts into tokens using spaCy\"\"\"\n",
    "    # List to store resulting tokens and docs\n",
    "    tokenized_data = []\n",
    "    docs = []\n",
    "\n",
    "    for text in data:\n",
    "        # detect text language\n",
    "        lang = detect(text)\n",
    "        # choose model according to the language\n",
    "        if lang == 'es':\n",
    "            doc = nlp_es(text)\n",
    "        elif lang == 'ca':\n",
    "            doc = nlp_ca(text)\n",
    "        else:\n",
    "            doc = nlp_es(text)\n",
    "\n",
    "        # split data into tokens, avoiding white space tokens\n",
    "        tokens = [token.text for token in doc if not token.is_space]\n",
    "        # add resulting list to the tokens list\n",
    "        tokenized_data.append(tokens)\n",
    "        docs.append(doc)\n",
    "\n",
    "    return tokenized_data, docs\n",
    "\n",
    "train_tokens, train_docs = tokenize_sentences(train_texts)\n",
    "test_tokens, test_docs = tokenize_sentences(test_texts)\n",
    "\n",
    "# Show an example of the tokenized text\n",
    "print(train_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map character-level annotations (e.g. `'start': 347, 'end': 350`) to token indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 71, 'NSCO')\n"
     ]
    }
   ],
   "source": [
    "def char_to_token_indices(texts, annotations_list):\n",
    "    #Maps character-level annotation spans to token indices using language-specific spaCy models.\n",
    "    all_token_annotations = []\n",
    "\n",
    "    for text, annotations in zip(texts, annotations_list):\n",
    "        # Detect language and choose the appropriate model\n",
    "        lang = detect(text)\n",
    "        if lang == 'es':\n",
    "            doc = nlp_es(text)\n",
    "        elif lang == 'ca':\n",
    "            doc = nlp_ca(text)\n",
    "        else:\n",
    "            doc = nlp_es(text) \n",
    "\n",
    "        token_annotations = []\n",
    "\n",
    "        for ann in annotations:\n",
    "            start, end = ann['start'], ann['end']\n",
    "            # Map character span to token span\n",
    "            span = doc.char_span(start, end, alignment_mode='contract')\n",
    "            if span:\n",
    "                token_annotations.append((span.start, span.end, ann['labels'][0]))\n",
    "\n",
    "        all_token_annotations.append(token_annotations)\n",
    "\n",
    "    return all_token_annotations\n",
    "\n",
    "train_token_annotations = char_to_token_indices(train_texts, train_annotations)\n",
    "test_token_annotations = char_to_token_indices(test_texts, test_annotations)\n",
    "\n",
    "print(train_token_annotations[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now, the indexes in `train_token_annotations` and `test_token_annotations` correspond to the tokens rather than to the characters, the label tells us whether it is a negation or uncertainty cue or scope.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we will do is to extract the dependency paths and PoS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nº', 'NOUN', 'det', 'historia'], ['historia', 'NOUN', 'ROOT', 'historia'], ['clinica', 'ADJ', 'amod', 'historia'], [':', 'PUNCT', 'punct', 'REDACTED'], ['REDACTED', 'PROPN', 'appos', 'historia'], ['REDACTED', 'PROPN', 'flat', 'REDACTED'], ['REDACTED', 'PROPN', 'flat', 'REDACTED'], ['nºepisodi', 'ADJ', 'amod', 'REDACTED'], [':', 'PUNCT', 'punct', 'REDACTED'], ['REDACTED', 'PROPN', 'appos', 'REDACTED'], ['sexe', 'PROPN', 'amod', 'REDACTED'], [':', 'PUNCT', 'punct', 'home'], ['home', 'PROPN', 'acl', 'REDACTED'], ['data', 'PROPN', 'flat', 'home'], ['de', 'ADP', 'case', 'naixement'], ['naixement', 'PROPN', 'flat', 'data'], [':', 'PUNCT', 'punct', 'edat'], ['16.05.1936', 'NUM', 'amod', 'edat'], ['edat', 'NOUN', 'obj', 'home'], [':', 'PUNCT', 'punct', 'data'], ['82', 'NUM', 'nummod', 'anys'], ['anys', 'PROPN', 'nsubj', 'data'], ['procedencia', 'PROPN', 'flat', 'anys'], ['cex', 'NOUN', 'flat', 'anys'], ['mateix', 'NOUN', 'amod', 'anys'], ['hosp', 'PROPN', 'flat', 'anys'], ['servei', 'PROPN', 'flat', 'anys'], ['urologia', 'PROPN', 'flat', 'servei'], ['data', 'VERB', 'appos', 'edat'], [\"d'ingres\", 'PROPN', 'flat', 'data'], ['24.07.2018', 'NUM', 'compound', 'data'], ['data', 'VERB', 'appos', 'edat'], [\"d'alta\", 'PROPN', 'flat', 'data'], ['25.07.2018', 'NUM', 'nmod', '08:54:04'], ['08:54:04', 'NUM', 'appos', 'edat'], ['ates', 'NOUN', 'obj', 'edat'], ['per', 'ADP', 'case', 'REDACTED'], ['REDACTED', 'PROPN', 'nmod', 'ates'], [',', 'PUNCT', 'punct', 'REDACTED'], ['REDACTED', 'PROPN', 'appos', 'edat'], [';', 'PUNCT', 'punct', 'REDACTED'], ['REDACTED', 'PROPN', 'conj', 'edat'], [',', 'PUNCT', 'punct', 'REDACTED'], ['REDACTED', 'PROPN', 'nsubj', 'informe'], ['informe', 'VERB', 'acl', 'edat'], [\"d'alta\", 'PROPN', 'obj', 'informe'], [\"d'hospitalitzacio\", 'PROPN', 'flat', \"d'alta\"], ['motiu', 'VERB', 'appos', 'edat'], [\"d'ingres\", 'PROPN', 'appos', 'edat'], ['paciente', 'ADJ', 'amod', \"d'ingres\"], ['que', 'PRON', 'nsubj', 'ingresa'], ['ingresa', 'VERB', 'acl', 'edat'], ['de', 'ADP', 'case', 'forma'], ['forma', 'NOUN', 'obl', 'ingresa'], ['programada', 'ADJ', 'amod', 'forma'], ['para', 'ADP', 'case', 'realizacion'], ['realizacion', 'PROPN', 'obl', 'ingresa'], ['de', 'ADP', 'case', 'uretrotomia'], ['uretrotomia', 'NOUN', 'nmod', 'realizacion'], ['interna', 'ADJ', 'amod', 'uretrotomia'], ['.', 'PUNCT', 'punct', 'historia'], ['antecedents', 'PROPN', 'ROOT', 'antecedents'], ['alergia', 'VERB', 'amod', 'antecedents'], ['a', 'ADP', 'case', 'penicilina'], ['penicilina', 'NOUN', 'nmod', 'antecedents'], ['y', 'CCONJ', 'cc', 'cloramfenicol'], ['cloramfenicol', 'VERB', 'conj', 'antecedents'], ['.', 'PUNCT', 'punct', 'antecedents'], ['no', 'ADV', 'advmod', 'habitos'], ['habitos', 'NOUN', 'ROOT', 'habitos'], ['toxicos', 'ADJ', 'amod', 'habitos'], ['.', 'PUNCT', 'punct', 'habitos'], ['antecedentes', 'NOUN', 'ROOT', 'antecedentes'], ['medicos', 'ADJ', 'amod', 'antecedentes'], [':', 'PUNCT', 'punct', 'bloqueo'], ['bloqueo', 'NOUN', 'appos', 'antecedentes'], ['auriculoventricular', 'VERB', 'acl', 'bloqueo'], ['de', 'ADP', 'case', 'grado'], ['primer', 'ADJ', 'amod', 'grado'], ['grado', 'NOUN', 'amod', 'hipertension'], ['hipertension', 'NOUN', 'obj', 'auriculoventricular'], ['arterial', 'ADJ', 'amod', 'hipertension'], ['.', 'PUNCT', 'punct', 'antecedentes'], ['diverticulosis', 'NOUN', 'nsubj', 'varon'], ['extensa', 'ADJ', 'amod', 'diverticulosis'], ['insuficiencia', 'NOUN', 'appos', 'diverticulosis'], ['renal', 'ADJ', 'amod', 'insuficiencia'], ['cronica', 'ADJ', 'amod', 'insuficiencia'], ['colelitiasis', 'ADJ', 'amod', 'diverticulosis'], ['antecedentes', 'NOUN', 'appos', 'diverticulosis'], ['quirurgicos', 'ADJ', 'amod', 'antecedentes'], [':', 'PUNCT', 'punct', 'exeresis'], ['exeresis', 'NOUN', 'nsubj', 'varon'], ['de', 'ADP', 'case', 'lesiones'], ['lesiones', 'NOUN', 'nmod', 'exeresis'], ['cutaneas', 'ADJ', 'amod', 'lesiones'], ['con', 'ADP', 'case', 'anestesia'], ['anestesia', 'NOUN', 'nmod', 'exeresis'], ['local', 'ADJ', 'amod', 'anestesia'], ['protesis', 'NOUN', 'appos', 'exeresis'], ['total', 'ADJ', 'amod', 'protesis'], ['de', 'ADP', 'case', 'cadera'], ['cadera', 'NOUN', 'nmod', 'protesis'], ['cordectomia', 'PROPN', 'appos', 'exeresis'], ['herniorrafia', 'PROPN', 'appos', 'exeresis'], ['inguinal', 'ADV', 'advmod', 'herniorrafia'], ['proces', 'ADJ', 'amod', 'exeresis'], ['actual', 'ADJ', 'amod', 'proces'], ['varon', 'VERB', 'ROOT', 'varon'], ['de', 'ADP', 'case', '81a'], ['81a', 'NUM', 'obl', 'varon'], ['que', 'SCONJ', 'mark', 'realiza'], ['a', 'ADP', 'case', 'raiz'], ['raiz', 'NOUN', 'obj', 'realiza'], ['de', 'ADP', 'case', 'episodio'], ['episodio', 'NOUN', 'nmod', 'raiz'], ['de', 'ADP', 'case', 'hematuria'], ['hematuria', 'NOUN', 'nmod', 'raiz'], ['macroscopica', 'ADJ', 'amod', 'hematuria'], ['se', 'PRON', 'expl:pass', 'realiza'], ['realiza', 'VERB', 'ccomp', 'varon'], ['cistoscopia', 'ADJ', 'obj', 'realiza'], ['que', 'PRON', 'nsubj', 'negativa'], ['es', 'AUX', 'cop', 'negativa'], ['negativa', 'ADJ', 'acl', 'cistoscopia'], ['para', 'ADP', 'case', 'lesiones'], ['lesiones', 'NOUN', 'nmod', 'negativa'], ['malignas', 'ADJ', 'amod', 'lesiones'], ['pero', 'CCONJ', 'cc', 'objetiva'], ['se', 'PRON', 'expl:pv', 'objetiva'], ['objetiva', 'VERB', 'conj', 'negativa'], ['estenosis', 'NOUN', 'nsubj', 'objetiva'], ['de', 'ADP', 'case', 'uretra'], ['uretra', 'PROPN', 'nmod', 'estenosis'], ['.', 'PUNCT', 'punct', 'varon'], ['se', 'PRON', 'expl:pass', 'intentan'], ['intentan', 'VERB', 'ROOT', 'intentan'], ['dilataciones', 'NOUN', 'nsubj', 'intentan'], ['progresivas', 'ADJ', 'amod', 'dilataciones'], ['en', 'ADP', 'case', 'gabinete'], ['el', 'DET', 'det', 'gabinete'], ['gabinete', 'NOUN', 'nmod', 'dilataciones'], ['de', 'ADP', 'case', 'urologia'], ['urologia', 'NOUN', 'nmod', 'gabinete'], ['sin', 'ADP', 'case', 'exito'], ['exito', 'NOUN', 'nmod', 'gabinete'], ['.', 'PUNCT', 'punct', 'intentan'], ['se', 'PRON', 'expl:pass', 'solicita'], ['solicita', 'VERB', 'ROOT', 'solicita'], ['estudio', 'NOUN', 'nsubj', 'solicita'], ['de', 'ADP', 'case', 'imagen'], ['imagen', 'NOUN', 'nmod', 'estudio'], ['que', 'PRON', 'nsubj', 'confirma'], ['confirma', 'VERB', 'acl', 'estudio'], ['la', 'DET', 'det', 'existencia'], ['existencia', 'NOUN', 'obj', 'confirma'], ['de', 'ADP', 'case', 'estenosis'], ['estenosis', 'NOUN', 'nmod', 'existencia'], ['a', 'ADP', 'case', 'nivel'], ['nivel', 'NOUN', 'nmod', 'estenosis'], ['d', 'PROPN', 'appos', 'estenosis'], ['uretra', 'PROPN', 'amod', 'estenosis'], ['bulbar', 'VERB', 'nsubj', 'solicita'], ['por', 'ADP', 'mark', 'indica'], ['lo', 'PRON', 'det', 'indica'], ['que', 'PRON', 'obl', 'indica'], ['se', 'PRON', 'expl:pass', 'indica'], ['indica', 'VERB', 'ccomp', 'bulbar'], ['uretrtomia', 'NOUN', 'nsubj', 'indica'], ['interna', 'ADJ', 'amod', 'uretrtomia'], ['.', 'PUNCT', 'punct', 'solicita'], ['exploracio', 'NOUN', 'nsubj', 'muestra'], ['complementaria', 'ADJ', 'amod', 'exploracio'], ['uretrocistografia', 'NOUN', 'appos', 'exploracio'], ['retrograda', 'ADJ', 'amod', 'exploracio'], ['+', 'PROPN', 'appos', 'exploracio'], ['cums', 'PROPN', 'flat', '+'], ['(', 'PUNCT', 'punct', '11/2017'], ['11/2017', 'NUM', 'flat', '+'], ['):', 'PUNCT', 'punct', '11/2017'], ['la', 'DET', 'det', 'uretrografia'], ['uretrografia', 'NOUN', 'nsubj', 'muestra'], ['retrograda', 'ADJ', 'amod', 'uretrografia'], ['muestra', 'VERB', 'ROOT', 'muestra'], ['una', 'DET', 'det', 'uretra'], ['uretra', 'NOUN', 'obj', 'muestra'], ['anterior', 'ADJ', 'amod', 'uretra'], ['con', 'ADP', 'case', 'estenosis'], ['dos', 'NUM', 'nummod', 'estenosis'], ['estenosis', 'NOUN', 'nmod', 'anterior'], ['focales', 'ADJ', 'amod', 'estenosis'], ['a', 'ADP', 'case', 'nivel'], ['nivel', 'NOUN', 'nmod', 'estenosis'], ['de', 'ADP', 'case', 'peneana'], ['uretra', 'PROPN', 'det', 'peneana'], ['peneana', 'NOUN', 'nmod', 'estenosis'], ['y', 'CCONJ', 'cc', 'bulbar'], ['bulbar', 'VERB', 'conj', 'peneana'], [',', 'PUNCT', 'punct', 'observa'], ['aunque', 'SCONJ', 'mark', 'observa'], ['se', 'PRON', 'expl:pass', 'observa'], ['observa', 'VERB', 'advcl', 'muestra'], ['paso', 'NOUN', 'obj', 'observa'], ['de', 'ADP', 'case', 'contraste'], ['contraste', 'NOUN', 'nmod', 'paso'], ['retrogrado', 'ADJ', 'amod', 'paso'], ['a', 'ADP', 'case', 'vejiga'], ['vejiga', 'PROPN', 'obj', 'retrogrado'], ['.', 'PUNCT', 'punct', 'muestra'], ['vejiga', 'VERB', 'ROOT', 'vejiga'], ['de', 'ADP', 'case', 'capacidad'], ['correcta', 'ADJ', 'amod', 'capacidad'], ['capacidad', 'NOUN', 'obj', 'vejiga'], ['(', 'PUNCT', 'punct', '250'], ['250', 'NUM', 'nummod', 'cc'], ['cc', 'PRON', 'obj', 'vejiga'], ['de', 'ADP', 'case', 'contraste'], ['contraste', 'NOUN', 'nmod', 'cc'], [')', 'PUNCT', 'punct', 'cc'], [',', 'PUNCT', 'punct', 'paredes'], ['de', 'ADP', 'case', 'paredes'], ['paredes', 'NOUN', 'obl', 'vejiga'], ['trabeculadas', 'ADJ', 'amod', 'paredes'], ['y', 'CCONJ', 'cc', 'diverticulos'], ['con', 'ADP', 'case', 'diverticulos'], ['diverticulos', 'NOUN', 'conj', 'paredes'], [',', 'PUNCT', 'punct', 'paredes'], ['el', 'DET', 'det', 'mayor'], ['mayor', 'ADJ', 'obj', 'vejiga'], ['de', 'ADP', 'case', 'ellos'], ['ellos', 'PRON', 'nmod', 'mayor'], ['en', 'ADP', 'case', 'cara'], ['cara', 'NOUN', 'nmod', 'mayor'], ['posterolateral', 'ADJ', 'amod', 'cara'], ['izquierda', 'ADJ', 'amod', 'cara'], [',', 'PUNCT', 'punct', 'observarse'], ['sin', 'ADP', 'mark', 'observarse'], ['observarse', 'VERB', 'advcl', 'vejiga'], ['defectos', 'NOUN', 'obj', 'observarse'], ['de', 'ADP', 'case', 'replecion'], ['replecion', 'PROPN', 'nmod', 'defectos'], ['.', 'PUNCT', 'punct', 'vejiga'], ['la', 'DET', 'det', 'uretrografia'], ['uretrografia', 'PROPN', 'nsubj', 'muestra'], ['miccional', 'ADJ', 'amod', 'uretrografia'], ['muestra', 'VERB', 'ROOT', 'muestra'], ['una', 'DET', 'det', 'prostatica'], ['uretra', 'ADJ', 'amod', 'prostatica'], ['prostatica', 'NOUN', 'obj', 'muestra'], ['dilatada', 'ADJ', 'amod', 'prostatica'], [',', 'PUNCT', 'punct', 'estenosis'], ['sin', 'ADP', 'case', 'estenosis'], ['claras', 'ADJ', 'amod', 'estenosis'], ['estenosis', 'NOUN', 'nmod', 'prostatica'], ['focales', 'ADJ', 'amod', 'estenosis'], ['confirmandose', 'VERB', 'acl', 'estenosis'], ['la', 'DET', 'det', 'existencia'], ['existencia', 'NOUN', 'obj', 'confirmandose'], ['de', 'ADP', 'case', 'estenosis'], ['las', 'DET', 'det', 'estenosis'], ['dos', 'NUM', 'nummod', 'las'], ['estenosis', 'NOUN', 'nmod', 'existencia'], ['de', 'ADP', 'case', 'uretra'], ['uretra', 'NOUN', 'nmod', 'estenosis'], ['anterior', 'ADJ', 'amod', 'descritas'], ['descritas', 'NOUN', 'appos', 'estenosis'], ['previamente', 'ADV', 'amod', 'descritas'], ['.', 'PUNCT', 'punct', 'muestra'], ['moderado', 'ADJ', 'amod', 'residuo'], ['residuo', 'NOUN', 'ROOT', 'residuo'], ['postmiccional', 'ADJ', 'amod', 'residuo'], ['en', 'ADP', 'case', 'vejiga'], ['vejiga', 'PROPN', 'nmod', 'residuo'], ['asi', 'PROPN', 'flat', 'vejiga'], ['como', 'SCONJ', 'mark', 'interior'], ['en', 'ADP', 'case', 'interior'], ['el', 'DET', 'det', 'interior'], ['interior', 'NOUN', 'nmod', 'residuo'], ['del', 'ADP', 'case', 'diverticulo'], ['diverticulo', 'NOUN', 'nmod', 'interior'], ['posterolateral', 'ADJ', 'amod', 'diverticulo'], ['izquierdo', 'ADJ', 'amod', 'diverticulo'], ['descrito', 'ADJ', 'amod', 'diverticulo'], ['.', 'PUNCT', 'punct', 'residuo'], ['uretroscopia', 'PROPN', 'nsubj', 'detecta'], ['(', 'PUNCT', 'punct', '10/2017'], ['10/2017', 'NUM', 'appos', 'uretroscopia'], [')', 'PUNCT', 'punct', '10/2017'], ['falsa', 'ADJ', 'amod', 'uretroscopia'], ['via', 'PROPN', 'appos', 'uretroscopia'], ['a', 'ADP', 'case', 'nivel'], ['nivel', 'NOUN', 'nmod', 'uretroscopia'], ['de', 'ADP', 'case', 'peneana'], ['uretra', 'PROPN', 'det', 'peneana'], ['peneana', 'NOUN', 'nmod', 'uretroscopia'], [',', 'PUNCT', 'punct', 'siguiendo'], ['siguiendo', 'VERB', 'advcl', 'detecta'], ['la', 'DET', 'det', 'uretra'], ['uretra', 'NOUN', 'obj', 'siguiendo'], ['se', 'PRON', 'expl:pv', 'detecta'], ['detecta', 'VERB', 'ROOT', 'detecta'], ['gran', 'ADJ', 'amod', 'estenosis'], ['estenosis', 'NOUN', 'obj', 'detecta'], ['que', 'PRON', 'nsubj', 'permite'], ['no', 'ADV', 'advmod', 'permite'], ['permite', 'VERB', 'acl', 'estenosis'], ['el', 'DET', 'det', 'paso'], ['paso', 'NOUN', 'obj', 'permite'], ['de', 'ADP', 'case', 'guia'], ['una', 'DET', 'det', 'guia'], ['guia', 'NOUN', 'nmod', 'paso'], ['.', 'PUNCT', 'punct', 'detecta'], ['nhc', 'DET', 'det', 'REDACTED'], ['REDACTED', 'PROPN', 'ROOT', 'REDACTED'], ['REDACTED', 'PROPN', 'flat', 'REDACTED'], ['REDACTED', 'PROPN', 'flat', 'REDACTED'], ['(', 'PUNCT', 'punct', 'REDACTED'], ['REDACTED', 'PROPN', 'flat', 'REDACTED'], [')', 'PUNCT', 'punct', 'REDACTED'], ['age-v-uro', 'NOUN', 'amod', 'REDACTED'], ['1/2', 'NUM', 'nummod', 'age-v-uro'], ['lopd', 'ADJ', 'amod', 'REDACTED'], ['evolucio', 'NOUN', 'obj', 'lopd'], ['clinica', 'ADJ', 'amod', 'evolucio'], ['el', 'DET', 'det', '24'], ['24', 'NUM', 'obl', 'lopd'], ['de', 'ADP', 'case', 'julio'], ['julio', 'NOUN', 'compound', '24'], ['de', 'ADP', 'case', '2018'], ['2018', 'NUM', 'compound', '24'], ['con', 'ADP', 'case', 'consentimiento'], ['el', 'DET', 'det', 'consentimiento'], ['consentimiento', 'NOUN', 'obl', 'lopd'], ['informado', 'ADJ', 'amod', 'consentimiento'], ['del', 'ADP', 'case', 'paciente'], ['paciente', 'NOUN', 'amod', 'informado'], ['y', 'CCONJ', 'cc', 'realiza'], ['sin', 'ADP', 'case', 'contraindicacion'], ['contraindicacion', 'PROPN', 'obl', 'realiza'], ['preoperatoria', 'ADJ', 'amod', 'contraindicacion'], ['se', 'PRON', 'expl:pass', 'realiza'], ['realiza', 'VERB', 'conj', 'lopd'], ['uretrotomia', 'NOUN', 'nsubj', 'realiza'], ['interna', 'ADJ', 'amod', 'uretrotomia'], ['sin', 'ADP', 'case', 'incidencias'], ['incidencias', 'NOUN', 'nmod', 'uretrotomia'], ['.', 'PUNCT', 'punct', 'REDACTED'], ['tras', 'ADP', 'case', 'procedimiento'], ['el', 'DET', 'det', 'procedimiento'], ['procedimiento', 'NOUN', 'obl', 'trasladado'], ['el', 'DET', 'det', 'paciente'], ['paciente', 'NOUN', 'nsubj', 'trasladado'], ['es', 'AUX', 'aux', 'trasladado'], ['trasladado', 'VERB', 'ROOT', 'trasladado'], ['a', 'ADP', 'case', 'planta'], ['la', 'DET', 'det', 'planta'], ['planta', 'NOUN', 'obl', 'trasladado'], ['de', 'ADP', 'case', 'hospitalizacion'], ['hospitalizacion', 'NOUN', 'nmod', 'planta'], ['siendo', 'AUX', 'cop', 'portador'], ['portador', 'ADJ', 'xcomp', 'trasladado'], ['de', 'ADP', 'case', 'lavado'], ['lavado', 'ADJ', 'nmod', 'portador'], ['vesical', 'ADJ', 'amod', 'lavado'], ['continuo', 'ADJ', 'amod', 'lavado'], ['.', 'PUNCT', 'punct', 'trasladado'], ['posteriormente', 'ADV', 'advmod', 'mantiene'], ['se', 'PRON', 'expl:pass', 'mantiene'], ['mantiene', 'VERB', 'ROOT', 'mantiene'], ['en', 'ADP', 'case', 'estado'], ['buen', 'ADJ', 'amod', 'estado'], ['estado', 'NOUN', 'obl', 'mantiene'], ['general', 'ADJ', 'amod', 'estado'], [',', 'PUNCT', 'punct', 'afebril'], ['afebril', 'NOUN', 'appos', 'estado'], [',', 'PUNCT', 'punct', 'afebril'], ['hemodinamicamente', 'ADV', 'advmod', 'estable'], ['estable', 'ADJ', 'amod', 'afebril'], ['y', 'CCONJ', 'cc', 'control'], ['con', 'ADP', 'case', 'control'], ['buen', 'ADJ', 'amod', 'control'], ['control', 'NOUN', 'conj', 'afebril'], ['del', 'ADP', 'case', 'dolor'], ['dolor', 'NOUN', 'nmod', 'control'], ['.', 'PUNCT', 'punct', 'mantiene'], ['aclarado', 'ADJ', 'ROOT', 'aclarado'], ['progresivo', 'ADJ', 'obj', 'aclarado'], ['de', 'ADP', 'case', 'orina'], ['la', 'DET', 'det', 'orina'], ['orina', 'NOUN', 'obj', 'aclarado'], ['con', 'ADP', 'case', 'lavados'], ['los', 'DET', 'det', 'lavados'], ['lavados', 'NOUN', 'obl', 'aclarado'], ['vesicales', 'ADJ', 'amod', 'lavados'], ['continuos', 'ADJ', 'amod', 'lavados'], [',', 'PUNCT', 'punct', 'permiten'], ['que', 'PRON', 'nsubj', 'permiten'], ['permiten', 'VERB', 'acl', 'lavados'], ['su', 'DET', 'det', 'retirada'], ['retirada', 'NOUN', 'obj', 'permiten'], [',', 'PUNCT', 'punct', 'permiten'], ['conserva', 'VERB', 'advcl', 'aclarado'], ['correcta', 'ADJ', 'amod', 'diuresis'], ['diuresis', 'NOUN', 'obj', 'conserva'], ['.', 'PUNCT', 'punct', 'aclarado'], ['tolerancia', 'NOUN', 'ROOT', 'tolerancia'], ['correcta', 'ADJ', 'amod', 'tolerancia'], ['a', 'ADP', 'case', 'dieta'], ['dieta', 'NOUN', 'nmod', 'correcta'], ['oral', 'ADJ', 'amod', 'dieta'], ['.', 'PUNCT', 'punct', 'tolerancia'], ['dada', 'VERB', 'advcl', 'decide'], ['la', 'DET', 'det', 'evolucion'], ['buena', 'ADJ', 'amod', 'evolucion'], ['evolucion', 'NOUN', 'nsubj', 'dada'], ['se', 'PRON', 'expl:pass', 'decide'], ['decide', 'VERB', 'ROOT', 'decide'], ['alta', 'ADJ', 'obj', 'decide'], ['domiciliaria', 'ADJ', 'amod', 'alta'], ['siendo', 'AUX', 'cop', 'portador'], ['portador', 'ADJ', 'advcl', 'decide'], ['de', 'ADP', 'case', 'sonda'], ['sonda', 'NOUN', 'nmod', 'portador'], ['vesical', 'ADJ', 'amod', 'sonda'], ['.', 'PUNCT', 'punct', 'decide'], ['orientacio', 'NOUN', 'nsubj', 'inferiors'], ['diagnostica', 'ADJ', 'amod', 'orientacio'], ['n40.0', 'PROPN', 'appos', 'orientacio'], ['hiperplasia', 'PROPN', 'flat', 'n40.0'], ['prostatica', 'ADJ', 'amod', 'orientacio'], ['benigna', 'NOUN', 'flat', 'orientacio'], ['sense', 'ADJ', 'amod', 'benigna'], ['simptomes', 'PROPN', 'appos', 'orientacio'], ['en', 'ADP', 'case', 'vies'], ['les', 'PRON', 'det', 'vies'], ['vies', 'NOUN', 'nmod', 'orientacio'], ['urinaries', 'PROPN', 'flat', 'vies'], ['inferiors', 'PROPN', 'ROOT', 'inferiors'], ['procediments', 'NOUN', 'obj', 'inferiors'], ['04.81', 'NUM', 'compound', 'procediments'], ['injeccio', 'ADJ', 'obj', 'inferiors'], ['en', 'ADP', 'case', 'nervi'], ['el', 'DET', 'det', 'nervi'], ['nervi', 'NOUN', 'obl', 'inferiors'], ['periferic', 'ADJ', 'advcl', 'inferiors'], [\"d'anestesic\", 'PROPN', 'flat', 'periferic'], ['per', 'ADP', 'case', 'analgesia'], ['a', 'ADP', 'case', 'analgesia'], ['analgesia', 'NOUN', 'obl', 'inferiors'], ['58.0', 'NUM', 'nummod', 'uretrotomia'], ['uretrotomia', 'NOUN', 'obj', 'inferiors'], ['.', 'PUNCT', 'punct', 'inferiors'], ['excisio', 'NOUN', 'ROOT', 'excisio'], ['de', 'ADP', 'case', 'septe'], ['septe', 'NOUN', 'nmod', 'excisio'], ['uretral', 'ADJ', 'amod', 'septe'], [',', 'PUNCT', 'punct', 'uretrostomia'], ['uretrostomia', 'PROPN', 'conj', 'excisio'], ['perineal', 'ADJ', 'amod', 'uretrostomia'], [',', 'PUNCT', 'punct', 'extraccio'], ['extraccio', 'NOUN', 'conj', 'excisio'], ['de', 'ADP', 'case', 'calcul'], ['calcul', 'PROPN', 'nmod', 'extraccio'], ['uretral', 'PROPN', 'amod', 'calcul'], ['per', 'ADP', 'case', 'incisio'], ['incisio', 'ADJ', 'amod', 'extraccio'], ['sonda', 'PROPN', 'flat', 'incisio'], ['vesical', 'ADJ', 'flat', 'sonda'], ['profilaxis', 'PROPN', 'flat', 'incisio'], ['antibiotica', 'ADJ', 'flat', 'profilaxis'], [',', 'PUNCT', 'punct', 'antilucerosa'], ['antilucerosa', 'ADJ', 'amod', 'profilaxis'], ['y', 'CCONJ', 'cc', 'antitrombotica'], ['antitrombotica', 'ADJ', 'conj', 'profilaxis'], ['tractament', 'PROPN', 'flat', 'incisio'], ['i', 'CCONJ', 'cc', 'recomanacions'], ['recomanacions', 'PROPN', 'conj', 'incisio'], ['a', 'ADP', 'case', \"l'alta\"], [\"l'alta\", 'PROPN', 'nmod', 'extraccio'], ['-abundante', 'ADV', 'advmod', 'ingesta'], ['ingesta', 'ADJ', 'amod', 'extraccio'], ['de', 'ADP', 'case', 'liquidos'], ['liquidos', 'NOUN', 'nmod', 'ingesta'], ['entorno', 'NOUN', 'amod', 'extraccio'], ['a', 'ADP', 'case', 'litros'], ['dos', 'NUM', 'nummod', 'litros'], ['litros', 'NOUN', 'nmod', 'entorno'], ['y', 'CCONJ', 'cc', 'medio'], ['medio', 'NUM', 'conj', 'litros'], ['de', 'ADP', 'case', 'agua'], ['agua', 'NOUN', 'nmod', 'litros'], ['al', 'ADP', 'case', 'dia'], ['dia', 'PROPN', 'nmod', 'entorno'], ['.', 'PUNCT', 'punct', 'excisio'], ['-puede', 'VERB', 'ROOT', '-puede'], ['orinar', 'VERB', 'csubj', '-puede'], ['con', 'ADP', 'case', 'restos'], ['restos', 'NOUN', 'obj', 'orinar'], ['de', 'ADP', 'case', 'sangre'], ['sangre', 'NOUN', 'nmod', 'restos'], ['durante', 'ADP', 'case', 'semanas'], ['las', 'DET', 'det', 'semanas'], ['proximas', 'ADJ', 'amod', 'semanas'], ['semanas', 'NOUN', 'obl', 'orinar'], ['.', 'PUNCT', 'punct', '-puede'], ['-es', 'PUNCT', 'ROOT', '-es'], ['normal', 'ADJ', 'iobj', '-es'], ['que', 'SCONJ', 'mark', 'sienta'], ['sienta', 'VERB', 'ccomp', 'normal'], ['escozor', 'NOUN', 'obj', 'sienta'], ['al', 'ADP', 'case', 'orinar'], ['orinar', 'VERB', 'advcl', 'sienta'], ['y', 'CCONJ', 'cc', 'tenga'], ['que', 'PRON', 'mark', 'tenga'], ['tenga', 'VERB', 'conj', 'orinar'], ['algun', 'PROPN', 'amod', 'escape'], ['escape', 'NOUN', 'obj', 'tenga'], ['de', 'ADP', 'case', 'orina'], ['orina', 'PROPN', 'nmod', 'escape'], ['y', 'CCONJ', 'cc', 'urgencia'], ['urgencia', 'NOUN', 'conj', 'orina'], ['miccional', 'ADJ', 'amod', 'urgencia'], ['al', 'ADP', 'case', 'retirar'], ['retirar', 'VERB', 'advcl', 'tenga'], ['la', 'DET', 'det', 'sonda'], ['sonda', 'NOUN', 'obj', 'retirar'], ['vesical', 'ADJ', 'amod', 'sonda'], ['.', 'PUNCT', 'punct', '-es'], ['mantener', 'VERB', 'ROOT', 'mantener'], ['sonda', 'NOUN', 'obj', 'mantener'], ['vesical', 'ADJ', 'amod', 'sonda'], ['durante', 'ADP', 'case', 'dias'], ['14', 'NUM', 'nummod', 'dias'], ['dias', 'NOUN', 'obl', 'mantener'], ['(', 'PUNCT', 'punct', 'semanas'], ['dos', 'NUM', 'nummod', 'semanas'], ['semanas', 'NOUN', 'appos', 'dias'], [')', 'PUNCT', 'punct', 'semanas'], ['.', 'PUNCT', 'punct', 'mantener'], ['ciprofloxacino', 'NOUN', 'det', 'cada'], ['500', 'NUM', 'appos', 'ciprofloxacino'], ['mg', 'PART', 'compound', '500'], ['cada', 'DET', 'nmod', '12h'], ['12h', 'NUM', 'ROOT', '12h'], ['durante', 'ADP', 'case', 'semanas'], ['dos', 'NUM', 'nummod', 'semanas'], ['semanas', 'NOUN', 'nmod', '12h'], ['.', 'PUNCT', 'punct', '12h'], ['-paracetamol', 'NOUN', 'ROOT', '-paracetamol'], ['1', 'NUM', 'appos', '-paracetamol'], ['g', 'CCONJ', 'cc', '8'], ['cada', 'DET', 'det', '8'], ['8', 'NUM', 'conj', '-paracetamol'], ['horas', 'NOUN', 'compound', '8'], ['si', 'SCONJ', 'mark', 'molestias'], ['molestias', 'NOUN', 'conj', '-paracetamol'], ['.', 'PUNCT', 'punct', '-paracetamol'], ['-si', 'ADP', 'ROOT', '-si'], ['fiebre', 'NOUN', 'obj', '-si'], ['mayor', 'ADJ', 'amod', 'fiebre'], ['de', 'ADP', 'case', '38ºc'], ['38ºc', 'NUM', 'nummod', 'fiebre'], [',', 'PUNCT', 'punct', 'empeoramiento'], ['empeoramiento', 'NOUN', 'appos', 'fiebre'], ['claro', 'ADJ', 'amod', 'empeoramiento'], ['del', 'ADP', 'case', 'estado'], ['estado', 'NOUN', 'nmod', 'empeoramiento'], ['general', 'ADJ', 'amod', 'estado'], ['o', 'CCONJ', 'cc', 'imposibilidad'], ['imposibilidad', 'NOUN', 'conj', 'estado'], ['miccional', 'ADJ', 'amod', 'imposibilidad'], ['por', 'ADP', 'case', 'obstruccion'], ['obstruccion', 'NOUN', 'nmod', 'empeoramiento'], ['de', 'ADP', 'case', 'sonda'], ['sonda', 'NOUN', 'nmod', 'obstruccion'], ['vesical', 'ADJ', 'amod', 'sonda'], ['o', 'CCONJ', 'cc', 'despues'], ['despues', 'NOUN', 'conj', 'obstruccion'], ['de', 'ADP', 'case', 'retirada'], ['su', 'DET', 'det', 'retirada'], ['retirada', 'NOUN', 'nmod', 'obstruccion'], [',', 'PUNCT', 'punct', 'empeoramiento'], ['consultar', 'VERB', 'xcomp', '-si'], ['con', 'ADP', 'case', 'servicio'], ['el', 'DET', 'det', 'servicio'], ['servicio', 'NOUN', 'obl', 'consultar'], ['de', 'ADP', 'case', 'urgencias'], ['urgencias', 'NOUN', 'nmod', 'servicio'], ['.', 'PUNCT', 'punct', '-si'], ['-control', 'DET', 'ROOT', '-control'], ['en', 'ADP', 'case', 'consultas'], ['consultas', 'NOUN', 'nmod', '-control'], ['externas', 'ADJ', 'amod', 'consultas'], ['de', 'ADP', 'case', 'urologia'], ['urologia', 'NOUN', 'nmod', 'consultas'], ['segun', 'PROPN', 'amod', 'consultas'], ['cita', 'NOUN', 'nmod', 'consultas'], ['en', 'ADP', 'case', 'hoja'], ['hoja', 'NOUN', 'nmod', 'consultas'], ['adjunta', 'ADJ', 'amod', 'hoja'], ['.', 'PUNCT', 'punct', '-control'], ['destinacio', 'NOUN', 'ROOT', 'destinacio'], ['a', 'ADP', 'case', \"l'alta\"], [\"l'alta\", 'PROPN', 'nmod', 'destinacio'], [':', 'PUNCT', 'punct', 'nhc'], ['a', 'ADP', 'case', 'nhc'], ['domicili', 'NOUN', 'fixed', 'a'], ['nhc', 'PROPN', 'nmod', 'destinacio'], ['REDACTED', 'PROPN', 'flat', 'nhc'], ['REDACTED', 'PROPN', 'flat', 'nhc'], ['REDACTED', 'PROPN', 'flat', 'nhc'], ['(', 'PUNCT', 'punct', 'REDACTED'], ['REDACTED', 'PROPN', 'flat', 'nhc'], [')', 'PUNCT', 'punct', 'REDACTED'], ['age-v-uro', 'ADJ', 'amod', '2/2'], ['2/2', 'NUM', 'conj', 'nhc'], ['lopd', 'ADJ', 'amod', 'nhc']]\n"
     ]
    }
   ],
   "source": [
    "def extract_token_info(docs):\n",
    "    #Extracts token info from a list of spaCy Doc objects\n",
    "    # List to store token information\n",
    "    all_token_info = []\n",
    "\n",
    "    # Iterate through each doc\n",
    "    for doc in docs:\n",
    "        token_info = []\n",
    "        # Iterate through every token\n",
    "        for token in doc:\n",
    "            # add token info if the token is not a whitespace\n",
    "            if not token.is_space:\n",
    "                token_info.append([\n",
    "                    token.text,\n",
    "                    token.pos_,\n",
    "                    token.dep_,\n",
    "                    token.head.text\n",
    "                ])\n",
    "                \n",
    "        all_token_info.append(token_info)\n",
    "    \n",
    "    return all_token_info\n",
    "\n",
    "train_token_info = extract_token_info(train_docs)\n",
    "test_token_info = extract_token_info(test_docs)\n",
    "\n",
    "# Show an example\n",
    "print(train_token_info[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue we will save tokens, PoS, and dependencies in a **CoNLL-U style format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conllu(docs, file_path):\n",
    "    \"\"\"Saves a list of spaCy docs to a CoNLL-U file\"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        for doc in docs:\n",
    "            for token in doc:\n",
    "                f.write(f\"{token.i+1}\\t{token.text}\\t{token.lemma_}\\t{token.pos_}\\t\"\n",
    "                        f\"{token.tag_}\\t_\\t{token.head.i+1 if token.head != token else 0}\\t\"\n",
    "                        f\"{token.dep_}\\t_\\t_\\n\")\n",
    "            f.write(\"\\n\")  # Blank line between sentences\n",
    "\n",
    "\n",
    "# Save train and test docs to CoNLL-U format\n",
    "save_conllu(train_docs, 'train_data.conllu')\n",
    "save_conllu(test_docs, 'test_data.conllu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature Extraction for Cue Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cues(docs, negation_cues, uncertainty_cues, cue_type='negation'):\n",
    "    \"\"\"\n",
    "    Extracts features and labels from spaCy docs for cue detection.\n",
    "    Use cue_type='negation' or 'uncertainty' to control which cues are labeled.\n",
    "    \"\"\"\n",
    "    affixal_cues = {'des', 'in', 'im', 'ir', 'a', 'anti', 'i', 'sin', 'sense'}\n",
    "    \n",
    "    # Select the appropriate cue set\n",
    "    if cue_type == 'negation':\n",
    "        cue_set = set(negation_cues)\n",
    "    elif cue_type == 'uncertainty':\n",
    "        cue_set = set(uncertainty_cues)\n",
    "    else:\n",
    "        raise ValueError(\"cue_type must be 'negation' or 'uncertainty'\")\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for doc in docs:\n",
    "        doc_features = []\n",
    "        doc_labels = []\n",
    "\n",
    "        for i, token in enumerate(doc):\n",
    "            word = token.text.lower()\n",
    "            lemma = token.lemma_.lower()\n",
    "\n",
    "            feats = {\n",
    "                'word': token.text,\n",
    "                'lemma': token.lemma_,\n",
    "                'pos': token.pos_,\n",
    "                'dep': token.dep_,\n",
    "                'prev_lemma': doc[i - 1].lemma_ if i > 0 else '<START>',\n",
    "                'next_lemma': doc[i + 1].lemma_ if i < len(doc) - 1 else '<END>'\n",
    "            }\n",
    "\n",
    "            # Affixal cue features\n",
    "            for prefix in affixal_cues:\n",
    "                if word.startswith(prefix):\n",
    "                    feats['prefix'] = prefix\n",
    "                    base = word[len(prefix):]\n",
    "                    feats['base_ngrams'] = [base[:n] for n in range(1, min(6, len(base) + 1))]\n",
    "                    break\n",
    "\n",
    "            # Label: 1 if token is in selected cue set\n",
    "            label = 1 if word in cue_set or lemma in cue_set else 0\n",
    "\n",
    "            doc_features.append(feats)\n",
    "            doc_labels.append(label)\n",
    "\n",
    "        all_features.append(doc_features)\n",
    "        all_labels.append(doc_labels)\n",
    "\n",
    "    return all_features, all_labels\n",
    "\n",
    "\n",
    "# Extract features and labels from training set\n",
    "X_neg_train, y_neg_train = extract_cues(train_docs, train_negation_cues, train_uncertainty_cues, cue_type='negation')\n",
    "X_unc_train, y_unc_train = extract_cues(train_docs, train_negation_cues, train_uncertainty_cues, cue_type='uncertainty')\n",
    "\n",
    "# Extract features and labels from test set\n",
    "X_neg_test, y_neg_test = extract_cues(test_docs, test_negation_cues, test_uncertainty_cues, cue_type='negation')\n",
    "X_unc_test, y_unc_test = extract_cues(test_docs, test_negation_cues, test_uncertainty_cues, cue_type='uncertainty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some of the examples in which a negation was detected: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text 1\n",
      "  - Word: 'no' | Lemma: 'no' | Label: 1\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n",
      "  - Word: 'falsa' | Lemma: 'falso' | Label: 1\n",
      "  - Word: 'no' | Lemma: 'no' | Label: 1\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n",
      "\n",
      "Text 2\n",
      "  - Word: 'no' | Lemma: 'no' | Label: 1\n",
      "  - Word: 'no' | Lemma: 'no' | Label: 1\n",
      "  - Word: 'no' | Lemma: 'no' | Label: 1\n",
      "\n",
      "Text 3\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n",
      "  - Word: 'no' | Lemma: 'no' | Label: 1\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n",
      "  - Word: 'no' | Lemma: 'no' | Label: 1\n",
      "  - Word: 'sin' | Lemma: 'sin' | Label: 1\n"
     ]
    }
   ],
   "source": [
    "for doc_idx, (feature_doc, label_doc) in enumerate(zip(X_unc_train, y_unc_train)):\n",
    "    if doc_idx >= 3:\n",
    "        break  \n",
    "    print(f\"\\nText {doc_idx + 1}\")\n",
    "    for token_feat, label in zip(feature_doc, label_doc):\n",
    "        if label == 1:\n",
    "            print(f\"  - Word: '{token_feat['word']}' | Lemma: '{token_feat['lemma']}' | Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Feature Extraction for Scope Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
